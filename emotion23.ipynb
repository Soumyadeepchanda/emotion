{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e00d54-a70c-413d-b089-300f32ce4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b076dd-f279-4803-bf06-a7a2b95c848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for training and testing data\n",
    "base_dir = 'archive'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b8d81-f5dc-46a8-bc6f-bc4ff1c0e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions and batch size\n",
    "img_width, img_height = 32, 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f692890-db3a-4bc7-ac0e-40d99dfa3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for training and testing data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c453e1-c6fe-4287-a60b-4c28d56f2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training and testing datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e774579-a8af-4d59-a765-7203683d9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images for different emotions\n",
    "emotions = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, emotion in enumerate(emotions, start=1):\n",
    "    img_path = os.path.join(train_dir, emotion, os.listdir(os.path.join(train_dir, emotion))[0])\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(emotion)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52e3ad-9020-4855-881a-bd05be68b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
    "    BatchNormalization(),  \n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),  \n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aeea10-ee2f-45d8-a8bd-03da33b6dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68a92f-590d-4871-b0c5-f59910e851a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "filepath = r'C:\\Users\\SOUMYADEEP\\Desktop\\Emotion\\emotion23.keras' \n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a20ab-d38e-4489-b25d-39a719017552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stop, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f791f8f-95f6-40bd-9d94-e0313573cf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ced68-6040-4717-8324-74a9e412d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss and accuracy\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d52a70-9805-46c5-8384-52198164b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_width, img_height), color_mode='grayscale')\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img)\n",
    "    emotion_labels = ['angry', 'happy', 'neutral', 'sad', 'surprised']\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    predicted_emotion = emotion_labels[predicted_class]\n",
    "    return predicted_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5e8b5-008d-44b7-acd6-b7b532d755b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the specified image\n",
    "img = tf.keras.preprocessing.image.load_img('archive/test/happy/im17.png', target_size=(img_width, img_height), color_mode='grayscale')\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Predict emotion for the specified image\n",
    "prediction = predict_emotion('archive/test/happy/im17.png')\n",
    "print(\"Predicted Emotion:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77226fe-c227-41cc-9dcd-5f949a7ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the specified image\n",
    "img = tf.keras.preprocessing.image.load_img('archive/test/neutral/im292.png', target_size=(img_width, img_height), color_mode='grayscale')\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Predict emotion for the specified image\n",
    "prediction = predict_emotion('archive/test/neutral/im292.png')\n",
    "print(\"Predicted Emotion:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb3aa3-f62c-4583-adc1-ae5bcb7d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the specified image\n",
    "img = tf.keras.preprocessing.image.load_img('archive/test/surprised/im141.png', target_size=(img_width, img_height), color_mode='grayscale')\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Predict emotion for the specified image\n",
    "prediction = predict_emotion('archive/test/surprised/im141.png')\n",
    "print(\"Predicted Emotion:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f290bb-7eea-4187-b6f5-e5d7756ad4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the specified image\n",
    "img = tf.keras.preprocessing.image.load_img('archive/test/sad/im1060.png', target_size=(img_width, img_height), color_mode='grayscale')\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Predict emotion for the specified image\n",
    "prediction = predict_emotion('archive/test/sad/im1060.png')\n",
    "print(\"Predicted Emotion:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9373a9-95a2-42df-a180-7477b29ad777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the specified image\n",
    "img = tf.keras.preprocessing.image.load_img('archive/test/angry/im204.png', target_size=(img_width, img_height), color_mode='grayscale')\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# Predict emotion for the specified image\n",
    "prediction = predict_emotion('archive/test/angry/im204.png')\n",
    "print(\"Predicted Emotion:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6961c64-92af-467c-9e6a-f361c5f23e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
